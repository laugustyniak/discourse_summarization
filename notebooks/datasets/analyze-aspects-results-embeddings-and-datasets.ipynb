{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from os.path import basename\n",
    "from typing import Dict, Callable\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm_notebook\n",
    "from operator import itemgetter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/home/laugustyniak/github/phd/sentiment-backend/')\n",
    "from aspects.analysis.nlp_architect import get_metrics, get_models_params_from_name, filter_datasets\n",
    "from aspects.analysis.statistics_dataset import get_unique_words_from_corpus, get_uni_and_multigram_aspects_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_skip = ['char-bilstm', 'char-lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_char_models(model_name):\n",
    "    return not any(m in model_name.as_posix() for m in models_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../models/glove.840B.300d/model-info-char-word-lstm-crf-10epochs-Restaurants_poria-train.conll.info'),\n",
       " PosixPath('../models/glove.840B.300d/model-info-char-word-bilstm-crf-10epochs-Restaurants_poria-train.conll.info'),\n",
       " PosixPath('../models/glove.840B.300d/model-info-char-word-lstm-crf-10epochs-Laptops_poria-train.conll.info'),\n",
       " PosixPath('../models/glove.840B.300d/model-info-char-word-bilstm-crf-10epochs-Laptops_poria-train.conll.info')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path('../models/glove.840B.300d/').glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex_results_order = ['word bilstm', 'char word bilstm', 'word bilstm crf', 'char word bilstm crf', 'word lstm', 'char word lstm', 'word lstm crf', 'char word lstm crf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_f1_metric(all_models_path=Path('../models-2/')):\n",
    "    model_f1_by_word_embedding = {}\n",
    "    \n",
    "    for word_embedding_models_path in all_models_path.glob('*'):\n",
    "        models_f1 = {}\n",
    "        models_paths = filter(skip_char_models, word_embedding_models_path.glob('*'))\n",
    "        models_metrics = get_metrics(models_paths)\n",
    "        \n",
    "        for model_name, model_metrics in models_metrics.items():\n",
    "            if model_name not in models_to_skip:\n",
    "                model_name = get_models_params_from_name(model_name)\n",
    "                models_f1[model_name] = model_metrics.f1 \n",
    "        \n",
    "        if models_f1:\n",
    "            model_f1_by_word_embedding[word_embedding_models_path.stem] = models_f1\n",
    "    \n",
    "    return pd.DataFrame.from_dict(model_f1_by_word_embedding).round(2).reindex(reindex_results_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l}\n",
      "\\toprule\n",
      "Empty DataFrame\n",
      "Columns: Index([], dtype='object')\n",
      "Index: Index(['word bilstm', 'char word bilstm', 'word bilstm crf',\n",
      "       'char word bilstm crf', 'word lstm', 'char word lstm', 'word lstm crf',\n",
      "       'char word lstm crf'],\n",
      "      dtype='object') \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word bilstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char word bilstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word bilstm crf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char word bilstm crf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char word lstm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word lstm crf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>char word lstm crf</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [word bilstm, char word bilstm, word bilstm crf, char word bilstm crf, word lstm, char word lstm, word lstm crf, char word lstm crf]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_models_f1_metric()\n",
    "print(df.to_latex())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('/home/laugustyniak/luk.augustyniak@gmail.com/Projects/PRELUDIUM/Artykuły/aspect-based sentiment 2018/laptops-aspects.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_metrics(models_metrics: Dict, title=None):\n",
    "#     pd.DataFrame.from_dict({\n",
    "#         get_models_params_from_name(k): v\n",
    "#         for k, v\n",
    "#         in list(models_metrics.items())\n",
    "#     }, orient='index').sort_index(axis=0).plot(kind='bar', figsize=(25,12), title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_metrics(models_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(models_metrics.items())\n",
    "\n",
    "# draw_metrics(dict(models_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for we_name, we_f1 in model_f1_by_word_embedding.items():\n",
    "#     draw_metrics(dict(we_f1), title=we_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_embedding_models_path in list(Path('../models').glob('*')):\n",
    "    models_f1 = []\n",
    "    \n",
    "    models_paths = word_embedding_models_path.glob('*10epoch*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check coverage of words in embeddings for aspect datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus iterator: 49475it [00:00, 1103036.70it/s]\n",
      "Corpus iterator: 53781it [00:00, 634647.03it/s]\n",
      "Corpus iterator: 12470it [00:00, 613978.32it/s]\n",
      "Corpus iterator: 13257it [00:00, 631173.81it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_words = get_unique_words_from_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(file_path):\n",
    "    with open(file_path, encoding='utf-8') as fp:\n",
    "        words = []\n",
    "        try:\n",
    "            for line in tqdm_notebook(fp, desc=file_path + ': embedding loading'):\n",
    "                line_fields = line.split()\n",
    "                if len(line_fields) < 5:\n",
    "                    continue\n",
    "                else:\n",
    "                    if line[0] == ' ':\n",
    "                        pass\n",
    "                    else:\n",
    "                        word = line_fields[0]\n",
    "                        try:\n",
    "                            pass\n",
    "                        except:\n",
    "                            continue\n",
    "                        words.append(word)\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_PATH = Path('/home/laugustyniak/data/embeddings/')\n",
    "\n",
    "EMBEDDINGS = [\n",
    "    'GoogleNews-vectors-negative300.txt',\n",
    "    'glove.6B.50d.txt',\n",
    "    'glove.6B.100d.txt',\n",
    "    'glove.6B.200d.txt',\n",
    "    'glove.6B.300d.txt',\n",
    "    'glove.twitter.27B.200d.txt',\n",
    "    'glove.42B.300d.txt',\n",
    "    'glove.840B.300d.txt',\n",
    "    'numberbatch-en.txt',\n",
    "    'crawl-300d-2M.vec',\n",
    "    'wiki-news-300d-1M-subword.vec',\n",
    "    'wiki-news-300d-1M.vec',\n",
    "    'bow2.words',\n",
    "    'bow2.contexts',\n",
    "    'bow5.words',\n",
    "    'bow5.contexts',\n",
    "    'deps.words',\n",
    "#     'deps.contexts',\n",
    "    'sota-google.txt',\n",
    "    'sota-retrofit-600.txt',\n",
    "    'sota-sswe-50.txt',\n",
    "    'sota-wiki-600.txt',\n",
    "    'sentic2vec.txt',\n",
    "    'lexvec.commoncrawl.ngramsubwords.300d.W.pos.vectors',\n",
    "    'lexvec.enwiki+newscrawl.300d.W.pos.vectors',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/GoogleNe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.6B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.6B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.6B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.6B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.tw…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.42…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/glove.84…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/numberba…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='/home/laugustyniak/data/embeddings/crawl-30…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/laugustyniak/data/embeddings/wiki-news-300d-1M-subword.vec'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-71f89f4371c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mword_embedding_vocabulalaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_embeddings_vocabularies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-71f89f4371c6>\u001b[0m in \u001b[0;36mget_word_embeddings_vocabularies\u001b[0;34m(word_embedding_names)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDINGS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     }\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-71f89f4371c6>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m     return {\n\u001b[1;32m      3\u001b[0m         \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDINGS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mword_embedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embedding_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     }\n",
      "\u001b[0;32m<ipython-input-24-b15f669272bf>\u001b[0m in \u001b[0;36mload_word_embeddings\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_word_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': embedding loading'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/laugustyniak/data/embeddings/wiki-news-300d-1M-subword.vec'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def get_word_embeddings_vocabularies(word_embedding_names):\n",
    "    return {\n",
    "        word_embedding_name: load_word_embeddings((EMBEDDINGS_PATH / word_embedding_name).as_posix())\n",
    "        for word_embedding_name \n",
    "        in tqdm_notebook(word_embedding_names)\n",
    "    }\n",
    "   \n",
    "word_embedding_vocabulalaries = get_word_embeddings_vocabularies(EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_coverage_with_word_embedding(corpus_words, word_embedding_vocabulalaries):\n",
    "    word_embedding_coverage = {}\n",
    "    for word_embedding_name, vocabulary in word_embedding_vocabulalaries.items():\n",
    "        word_embedding_coverage[word_embedding_name] = {\n",
    "            corpus_name: len(words.difference(vocabulary))/len(words)\n",
    "            for corpus_name, words\n",
    "            in corpus_words.items()\n",
    "        }\n",
    "    return word_embedding_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: len(v) for k, v in  corpus_words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_words['Restaurants_poria-test'] - corpus_words['Restaurants_poria-train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_words['Laptops_poria-test'] - corpus_words['Laptops_poria-train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glove.6B.50d.txt': 400000,\n",
       " 'glove.6B.100d.txt': 400000,\n",
       " 'glove.6B.300d.txt': 400000,\n",
       " 'glove.twitter.27B.200d.txt': 1193515,\n",
       " 'glove.42B.300d.txt': 1917494,\n",
       " 'glove.840B.300d.txt': 2195884,\n",
       " 'numberbatch-en.txt': 417194,\n",
       " 'crawl-300d-2M.vec': 1999995,\n",
       " 'bow2.words': 183870,\n",
       " 'bow2.contexts': 183870,\n",
       " 'bow5.words': 183870,\n",
       " 'bow5.contexts': 183870,\n",
       " 'deps.words': 174015,\n",
       " 'deps.contexts': 561754,\n",
       " 'sota-google.txt': 60349,\n",
       " 'sota-retrofit-600.txt': 29444,\n",
       " 'sota-sswe-50.txt': 137052,\n",
       " 'sota-wiki-600.txt': 29444,\n",
       " 'sentic2vec.txt': 42007}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{word_embedding_name: len(vocabulary) for word_embedding_name, vocabulary in word_embedding_vocabulalaries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_coverage_with_word_embedding = get_datasets_coverage_with_word_embedding(corpus_words, word_embedding_vocabulalaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lack_of_words_percentage = pd.DataFrame(datasets_coverage_with_word_embedding).round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glove.6B.50d.txt</th>\n",
       "      <th>glove.6B.100d.txt</th>\n",
       "      <th>glove.6B.300d.txt</th>\n",
       "      <th>glove.twitter.27B.200d.txt</th>\n",
       "      <th>glove.42B.300d.txt</th>\n",
       "      <th>glove.840B.300d.txt</th>\n",
       "      <th>numberbatch-en.txt</th>\n",
       "      <th>crawl-300d-2M.vec</th>\n",
       "      <th>bow2.words</th>\n",
       "      <th>bow2.contexts</th>\n",
       "      <th>bow5.words</th>\n",
       "      <th>bow5.contexts</th>\n",
       "      <th>deps.words</th>\n",
       "      <th>deps.contexts</th>\n",
       "      <th>sota-google.txt</th>\n",
       "      <th>sota-retrofit-600.txt</th>\n",
       "      <th>sota-sswe-50.txt</th>\n",
       "      <th>sota-wiki-600.txt</th>\n",
       "      <th>sentic2vec.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Laptops_poria-test</th>\n",
       "      <td>4.27</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.27</td>\n",
       "      <td>8.17</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.24</td>\n",
       "      <td>9.83</td>\n",
       "      <td>2.39</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.66</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.51</td>\n",
       "      <td>12.54</td>\n",
       "      <td>6.14</td>\n",
       "      <td>12.54</td>\n",
       "      <td>17.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laptops_poria-train</th>\n",
       "      <td>9.18</td>\n",
       "      <td>9.18</td>\n",
       "      <td>9.18</td>\n",
       "      <td>11.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.20</td>\n",
       "      <td>14.06</td>\n",
       "      <td>4.32</td>\n",
       "      <td>11.02</td>\n",
       "      <td>11.02</td>\n",
       "      <td>11.02</td>\n",
       "      <td>11.02</td>\n",
       "      <td>11.23</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.92</td>\n",
       "      <td>20.86</td>\n",
       "      <td>11.99</td>\n",
       "      <td>20.86</td>\n",
       "      <td>18.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurants_poria-test</th>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>8.63</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.36</td>\n",
       "      <td>9.12</td>\n",
       "      <td>4.27</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.53</td>\n",
       "      <td>11.10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.91</td>\n",
       "      <td>21.81</td>\n",
       "      <td>9.87</td>\n",
       "      <td>21.81</td>\n",
       "      <td>32.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurants_poria-train</th>\n",
       "      <td>10.78</td>\n",
       "      <td>10.78</td>\n",
       "      <td>10.78</td>\n",
       "      <td>11.99</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.11</td>\n",
       "      <td>13.70</td>\n",
       "      <td>5.98</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.38</td>\n",
       "      <td>15.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>26.65</td>\n",
       "      <td>28.38</td>\n",
       "      <td>14.09</td>\n",
       "      <td>28.38</td>\n",
       "      <td>34.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         glove.6B.50d.txt  glove.6B.100d.txt  \\\n",
       "Laptops_poria-test                   4.27               4.27   \n",
       "Laptops_poria-train                  9.18               9.18   \n",
       "Restaurants_poria-test               7.40               7.40   \n",
       "Restaurants_poria-train             10.78              10.78   \n",
       "\n",
       "                         glove.6B.300d.txt  glove.twitter.27B.200d.txt  \\\n",
       "Laptops_poria-test                    4.27                        8.17   \n",
       "Laptops_poria-train                   9.18                       11.70   \n",
       "Restaurants_poria-test                7.40                        8.63   \n",
       "Restaurants_poria-train              10.78                       11.99   \n",
       "\n",
       "                         glove.42B.300d.txt  glove.840B.300d.txt  \\\n",
       "Laptops_poria-test                     1.77                 2.24   \n",
       "Laptops_poria-train                    3.40                 4.20   \n",
       "Restaurants_poria-test                 3.66                 4.36   \n",
       "Restaurants_poria-train                5.00                 6.11   \n",
       "\n",
       "                         numberbatch-en.txt  crawl-300d-2M.vec  bow2.words  \\\n",
       "Laptops_poria-test                     9.83               2.39        6.71   \n",
       "Laptops_poria-train                   14.06               4.32       11.02   \n",
       "Restaurants_poria-test                 9.12               4.27       10.53   \n",
       "Restaurants_poria-train               13.70               5.98       14.38   \n",
       "\n",
       "                         bow2.contexts  bow5.words  bow5.contexts  deps.words  \\\n",
       "Laptops_poria-test                6.71        6.71           6.71        6.66   \n",
       "Laptops_poria-train              11.02       11.02          11.02       11.23   \n",
       "Restaurants_poria-test           10.53       10.53          10.53       11.10   \n",
       "Restaurants_poria-train          14.38       14.38          14.38       15.26   \n",
       "\n",
       "                         deps.contexts  sota-google.txt  \\\n",
       "Laptops_poria-test               100.0            10.51   \n",
       "Laptops_poria-train              100.0            18.92   \n",
       "Restaurants_poria-test           100.0            19.91   \n",
       "Restaurants_poria-train          100.0            26.65   \n",
       "\n",
       "                         sota-retrofit-600.txt  sota-sswe-50.txt  \\\n",
       "Laptops_poria-test                       12.54              6.14   \n",
       "Laptops_poria-train                      20.86             11.99   \n",
       "Restaurants_poria-test                   21.81              9.87   \n",
       "Restaurants_poria-train                  28.38             14.09   \n",
       "\n",
       "                         sota-wiki-600.txt  sentic2vec.txt  \n",
       "Laptops_poria-test                   12.54           17.17  \n",
       "Laptops_poria-train                  20.86           18.55  \n",
       "Restaurants_poria-test               21.81           32.20  \n",
       "Restaurants_poria-train              28.38           34.38  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lack_of_words_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus iterator: 49475it [00:00, 524886.09it/s]\n",
      "Corpus iterator: 53781it [00:00, 661840.76it/s]\n",
      "Corpus iterator: 12470it [00:00, 770907.21it/s]\n",
      "Corpus iterator: 13257it [00:00, 708889.67it/s]\n"
     ]
    }
   ],
   "source": [
    "aspects = get_uni_and_multigram_aspects_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Multi aspect  \\\\\n",
      "\\midrule\n",
      "Restaurants\\_poria-train &          24.77 \\\\\n",
      "Laptops\\_poria-train     &          36.94 \\\\\n",
      "Laptops\\_poria-test      &          44.63 \\\\\n",
      "Restaurants\\_poria-test  &          27.75 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.from_dict(aspects, orient='index', columns=['Multi aspect ']).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words/aspects appeared in test data but not in training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_words' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5e87d35062d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_words' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "corpus_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
